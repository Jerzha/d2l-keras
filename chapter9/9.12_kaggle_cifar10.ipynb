{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 9.12 实战Kaggle比赛：图像分类（CIFAR-10）\n",
    "该比赛的网页地址是 https://www.kaggle.com/c/cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import d2lzh as d2l\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 9.12.1 获取和整理数据集\n",
    "#### 9.12.1.1 下载数据集\n",
    "#### 9.12.1.2 解压数据集\n",
    "\n",
    "下载完训练数据集train.7z和测试数据集test.7z后需要解压缩。解压缩后，将训练数据集、测试数据集以及训练数据集标签分别存放在以下3个路径：\n",
    "\n",
    "* ../data/kaggle_cifar10/train/[1-50000].png；\n",
    "* ../data/kaggle_cifar10/test/[1-300000].png；\n",
    "* ../data/kaggle_cifar10/trainLabels.csv\n",
    "\n",
    "#### 9.12.1.3 整理数据集\n",
    "我们需要整理数据集，以方便训练和测试模型。以下的read_label_file函数将用来读取训练数据集的标签文件。该函数中的参数valid_ratio是验证集样本数与原始训练集样本数之比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.png</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.png</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  1.png   frog\n",
       "1  2.png  truck\n",
       "2  3.png  truck\n",
       "3  4.png   deer"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/kaggle_cifar10/trainLabels.csv')\n",
    "train_data['id'] = train_data['id'].apply(lambda i: str(i)+'.png')\n",
    "test_data = pd.read_csv('data/kaggle_cifar10/sampleSubmission.csv')\n",
    "test_data['id'] = test_data['id'].apply(lambda i: str(i)+'.png')\n",
    "train_data.iloc[0:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在这里只使用100个训练样本和1个测试样本。训练数据集和测试数据集的文件夹名称分别为train_tiny和test_tiny。相应地，我们仅将批量大小设为1。实际训练和测试时应使用Kaggle比赛的完整数据集，并将批量大小batch_size设为一个较大的整数，如128。我们将10%的训练样本作为调参使用的验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, test_dir, batch_size = 'train', 'test', 128\n",
    "data_dir, label_file = 'data/kaggle_cifar10', 'trainLabels.csv'\n",
    "#input_dir, valid_ratio = 'train_valid_test', 0.1\n",
    "#reorg_cifar10_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.12.2 图像增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    zoom_range=(0.64, 1),\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "transform_train.mean = 127.5\n",
    "transform_train.std = 127.5\n",
    "\n",
    "transform_test = keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True\n",
    ")\n",
    "\n",
    "transform_test.mean = 127.5\n",
    "transform_test.std = 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.12.3 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 validated image filenames belonging to 10 classes.\n",
      "Found 5000 validated image filenames belonging to 10 classes.\n",
      "Found 300000 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = transform_train.flow_from_dataframe(\n",
    "    train_data, \n",
    "    os.path.join(data_dir, 'train'), \n",
    "    x_col='id', y_col='label',\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(32, 32), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='training')\n",
    "\n",
    "val_ds = transform_train.flow_from_dataframe(\n",
    "    train_data, \n",
    "    os.path.join(data_dir, 'train'), \n",
    "    x_col='id', y_col='label',\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(32, 32), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    subset='validation')\n",
    "\n",
    "test_ds = transform_test.flow_from_dataframe(\n",
    "    test_data, \n",
    "    os.path.join(data_dir, 'test'), \n",
    "    x_col='id', y_col='label',\n",
    "    target_size=(32, 32), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.12.4 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(keras.layers.Layer):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.conv1 = keras.layers.Conv2D(num_channels, kernel_size=3, padding='same', strides=strides)\n",
    "        self.conv2 = keras.layers.Conv2D(num_channels, kernel_size=3, padding='same')\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = keras.layers.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.relu1 = keras.layers.ReLU()\n",
    "        self.relu2 = keras.layers.ReLU()\n",
    "\n",
    "    def call(self, X):\n",
    "        Y = self.relu1(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return self.relu2(Y + X)\n",
    "\n",
    "def resnet18(num_classes):\n",
    "    inputs = keras.Input((32, 32, 3))\n",
    "    x = keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    def resnet_block(x, num_channels, num_residuals, first_block=False):\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                x = Residual(num_channels, use_1x1conv=True, strides=2)(x)\n",
    "            else:\n",
    "                x = Residual(num_channels)(x)\n",
    "        return x\n",
    "\n",
    "    x = resnet_block(x, 64, 2, first_block=True)\n",
    "    x = resnet_block(x, 128, 2)\n",
    "    x = resnet_block(x, 256, 2)\n",
    "    x = resnet_block(x, 512, 2)\n",
    "    x = keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = keras.layers.Dense(num_classes)(x)\n",
    "    x = keras.layers.Softmax()(x)\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():   \n",
    "    num_classes = 10\n",
    "    net = resnet18(num_classes)\n",
    "    net.compile(optimizer='adam', \n",
    "                loss=keras.losses.categorical_crossentropy,\n",
    "                metrics=['acc'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.12.5 定义训练函数\n",
    "### 9.12.6 训练并验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0129 23:55:55.609424 140296452523840 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "residual (Residual)          (None, 32, 32, 64)        74368     \n",
      "_________________________________________________________________\n",
      "residual_1 (Residual)        (None, 32, 32, 64)        74368     \n",
      "_________________________________________________________________\n",
      "residual_2 (Residual)        (None, 16, 16, 128)       230784    \n",
      "_________________________________________________________________\n",
      "residual_3 (Residual)        (None, 16, 16, 128)       296192    \n",
      "_________________________________________________________________\n",
      "residual_4 (Residual)        (None, 8, 8, 256)         920320    \n",
      "_________________________________________________________________\n",
      "residual_5 (Residual)        (None, 8, 8, 256)         1182208   \n",
      "_________________________________________________________________\n",
      "residual_6 (Residual)        (None, 4, 4, 512)         3675648   \n",
      "_________________________________________________________________\n",
      "residual_7 (Residual)        (None, 4, 4, 512)         4723712   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 11,184,778\n",
      "Trainable params: 11,176,970\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "352/352 [==============================] - 30s 86ms/step - loss: 0.9576 - acc: 0.6600 - val_loss: 1.4370 - val_acc: 0.5590\n",
      "Epoch 2/5\n",
      "352/352 [==============================] - 29s 83ms/step - loss: 0.7570 - acc: 0.7347 - val_loss: 0.9593 - val_acc: 0.6800\n",
      "Epoch 3/5\n",
      "352/352 [==============================] - 29s 82ms/step - loss: 0.6303 - acc: 0.7787 - val_loss: 0.8864 - val_acc: 0.7154\n",
      "Epoch 4/5\n",
      "352/352 [==============================] - 29s 84ms/step - loss: 0.5521 - acc: 0.8089 - val_loss: 0.6393 - val_acc: 0.7858\n",
      "Epoch 5/5\n",
      "352/352 [==============================] - 29s 83ms/step - loss: 0.4969 - acc: 0.8278 - val_loss: 0.7748 - val_acc: 0.7412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f988f989e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit_generator(train_ds, epochs=5, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.12.7 对测试集分类并在Kaggle提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net.predict_generator(test_ds)\n",
    "classes = np.argmax(pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id       label\n",
       "0  1        deer\n",
       "1  2    airplane\n",
       "2  3  automobile\n",
       "3  4        ship"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['id'] = test_data['id'].apply(lambda x: x[:-4])\n",
    "test_data['label'] = classes\n",
    "test_data['label'] = test_data['label'].apply(lambda x: str(list(train_ds.class_indices.keys())[x]))\n",
    "test_data.iloc[0:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}